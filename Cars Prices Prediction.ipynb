{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6cbc1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required Libraries\n",
    "import copy, math\n",
    "import numpy as np  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "08bdb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "data = pd.read_csv(r'D:\\Machine Learning\\Projects\\Cars Prices Prediction\\Dataset\\cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ae261f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enginesize</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>136</td>\n",
       "      <td>177.3</td>\n",
       "      <td>66.3</td>\n",
       "      <td>53.1</td>\n",
       "      <td>15250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>136</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>17710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>136</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>18920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>131</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.9</td>\n",
       "      <td>23875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>131</td>\n",
       "      <td>178.2</td>\n",
       "      <td>67.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enginesize  carlength  carwidth  carheight  price\n",
       "0         130      168.8      64.1       48.8  13495\n",
       "1         130      168.8      64.1       48.8  16500\n",
       "2         152      171.2      65.5       52.4  16500\n",
       "3         109      176.6      66.2       54.3  13950\n",
       "4         136      176.6      66.4       54.3  17450\n",
       "5         136      177.3      66.3       53.1  15250\n",
       "6         136      192.7      71.4       55.7  17710\n",
       "7         136      192.7      71.4       55.7  18920\n",
       "8         131      192.7      71.4       55.9  23875\n",
       "9         131      178.2      67.9       52.0  17859"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb5b7e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 5)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38e41e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 4)\n",
      "(99,)\n"
     ]
    }
   ],
   "source": [
    "#Grab features and label from dataframe\n",
    "X_train = data[['enginesize', 'carlength', 'carwidth', 'carheight']].values\n",
    "y_train = data['price'].values\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1ded903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa0171",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3\"></a>\n",
    "# Model Prediction With Multiple Variables\n",
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`\n",
    "\n",
    "To demonstrate the dot product, we will implement prediction using (1) and (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d354324",
   "metadata": {},
   "source": [
    "## Single Prediction, vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2ace2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4c392",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_4\"></a>\n",
    "# Compute Cost With Multiple Variables\n",
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "In contrast to previous labs, $\\mathbf{w}$ and $\\mathbf{x}^{(i)}$ are vectors rather than scalars supporting multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85a6ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451b10a",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5\"></a>\n",
    "# Gradient Descent With Multiple Variables\n",
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001cf55",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5.1\"></a>\n",
    "## Compute Gradient with Multiple Variables\n",
    "An implementation for calculating the equations (6) and (7) is below. There are many ways to implement this. In this version, there is an\n",
    "- outer loop over all m examples. \n",
    "    - $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ for the example can be computed directly and accumulated\n",
    "    - in a second loop over all n features:\n",
    "        - $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$ is computed for each $w_j$.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "745bd8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fbfe1",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5.2\"></a>\n",
    "## Gradient Descent With Multiple Variables\n",
    "The routine below implements equation (5) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "186f6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7286b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 136296982.36   \n",
      "Iteration  100: Cost 25089987.70   \n",
      "Iteration  200: Cost 22536388.59   \n",
      "Iteration  300: Cost 20694964.95   \n",
      "Iteration  400: Cost 19092017.01   \n",
      "Iteration  500: Cost 17695290.61   \n",
      "Iteration  600: Cost 16478230.88   \n",
      "Iteration  700: Cost 15417707.90   \n",
      "Iteration  800: Cost 14493569.47   \n",
      "Iteration  900: Cost 13688257.78   \n",
      "b,w found by gradient descent: -0.13,[104.45826211   9.62946688  -2.77674058  -5.09518861] \n",
      "prediction: 14778.26, target value: 13495\n",
      "prediction: 14778.26, target value: 16500\n",
      "prediction: 17077.22, target value: 16500\n",
      "prediction: 12625.89, target value: 13950\n",
      "prediction: 15445.71, target value: 17450\n",
      "prediction: 15458.84, target value: 15250\n",
      "prediction: 15579.73, target value: 17710\n",
      "prediction: 15579.73, target value: 18920\n",
      "prediction: 15056.42, target value: 23875\n",
      "prediction: 14946.38, target value: 17859\n",
      "prediction: 12527.25, target value: 16430\n",
      "prediction: 12527.25, target value: 16925\n",
      "prediction: 18376.91, target value: 20970\n",
      "prediction: 18376.91, target value: 21105\n",
      "prediction: 18481.43, target value: 24565\n",
      "prediction: 23182.05, target value: 30760\n",
      "prediction: 23235.68, target value: 41315\n",
      "prediction: 23244.92, target value: 36880\n",
      "prediction: 7292.04, target value: 5151\n",
      "prediction: 10460.79, target value: 6295\n",
      "prediction: 10488.72, target value: 6575\n",
      "prediction: 10479.83, target value: 5572\n",
      "prediction: 10479.83, target value: 6377\n",
      "prediction: 11315.50, target value: 7957\n",
      "prediction: 10480.85, target value: 6229\n",
      "prediction: 10480.85, target value: 6692\n",
      "prediction: 10480.85, target value: 7609\n",
      "prediction: 11316.52, target value: 8558\n",
      "prediction: 13941.01, target value: 8921\n",
      "prediction: 17523.30, target value: 12964\n",
      "prediction: 10566.18, target value: 6479\n",
      "prediction: 10566.18, target value: 6855\n",
      "prediction: 9250.77, target value: 5399\n",
      "prediction: 10608.73, target value: 6529\n",
      "prediction: 10608.73, target value: 7129\n",
      "prediction: 10728.08, target value: 7295\n",
      "prediction: 10648.33, target value: 7295\n",
      "prediction: 12650.59, target value: 7895\n",
      "prediction: 12650.59, target value: 9095\n",
      "prediction: 12722.59, target value: 8845\n",
      "prediction: 12730.09, target value: 10295\n",
      "prediction: 12722.59, target value: 12945\n",
      "prediction: 12675.50, target value: 10345\n",
      "prediction: 12794.29, target value: 6785\n",
      "prediction: 10460.79, target value: 8916\n",
      "prediction: 10460.79, target value: 8916\n",
      "prediction: 13649.51, target value: 11048\n",
      "prediction: 28409.85, target value: 32250\n",
      "prediction: 28409.85, target value: 35550\n",
      "prediction: 35459.64, target value: 36000\n",
      "prediction: 10583.70, target value: 5195\n",
      "prediction: 10583.70, target value: 6095\n",
      "prediction: 10583.70, target value: 6795\n",
      "prediction: 10657.85, target value: 6695\n",
      "prediction: 10657.85, target value: 7395\n",
      "prediction: 8504.17, target value: 10945\n",
      "prediction: 8504.17, target value: 11845\n",
      "prediction: 8504.17, target value: 13645\n",
      "prediction: 9548.75, target value: 15645\n",
      "prediction: 13997.63, target value: 8845\n",
      "prediction: 13988.46, target value: 8495\n",
      "prediction: 13997.63, target value: 10595\n",
      "prediction: 13988.46, target value: 10245\n",
      "prediction: 13988.46, target value: 10795\n",
      "prediction: 13988.46, target value: 11245\n",
      "prediction: 15848.46, target value: 18280\n",
      "prediction: 15221.71, target value: 18344\n",
      "prediction: 20470.91, target value: 25552\n",
      "prediction: 20459.70, target value: 28248\n",
      "prediction: 20446.32, target value: 28176\n",
      "prediction: 20580.71, target value: 31600\n",
      "prediction: 25907.06, target value: 34184\n",
      "prediction: 25724.70, target value: 35056\n",
      "prediction: 33688.91, target value: 40960\n",
      "prediction: 33191.17, target value: 45400\n",
      "prediction: 15873.89, target value: 16503\n",
      "prediction: 10687.08, target value: 5389\n",
      "prediction: 10687.08, target value: 6189\n",
      "prediction: 10687.08, target value: 6669\n",
      "prediction: 11315.50, target value: 7689\n",
      "prediction: 12722.87, target value: 9959\n",
      "prediction: 13976.37, target value: 8499\n",
      "prediction: 17523.30, target value: 12629\n",
      "prediction: 17523.30, target value: 14869\n",
      "prediction: 17523.30, target value: 14489\n",
      "prediction: 13959.38, target value: 6989\n",
      "prediction: 13959.38, target value: 8189\n",
      "prediction: 12705.89, target value: 9279\n",
      "prediction: 12705.89, target value: 9279\n",
      "prediction: 11269.23, target value: 5499\n",
      "prediction: 11895.97, target value: 7099\n",
      "prediction: 11269.23, target value: 6649\n",
      "prediction: 11269.23, target value: 6849\n",
      "prediction: 11321.50, target value: 7349\n",
      "prediction: 11269.23, target value: 7299\n",
      "prediction: 11278.23, target value: 7799\n",
      "prediction: 11269.23, target value: 7499\n",
      "prediction: 11321.50, target value: 7999\n",
      "prediction: 11247.41, target value: 8249\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "72fbb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predict(X_train, w_final, b_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
